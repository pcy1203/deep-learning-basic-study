[Google Colab](https://colab.research.google.com/drive/1ARPBH3agNvQ_xYzm_xyEmP7cWIzC4gFE?usp=sharing)

### **ğŸ“Œ 4.1. ~ 4.2. ì¸ê³µ ì‹ ê²½ë§ì˜ í•œê³„ì™€ ë”¥ëŸ¬ë‹ ì¶œí˜„ / ë”¥ëŸ¬ë‹ êµ¬ì¡°**

- **ë”¥ëŸ¬ë‹ì˜ ì •ì˜**
    - **í¼ì…‰íŠ¸ë¡ ** : ë”¥ëŸ¬ë‹ì˜ ê¸°ì›ì´ ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜, ë‹¤ìˆ˜ì˜ ì‹ í˜¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í•˜ë‚˜ì˜ ì‹ í˜¸ë¥¼ ì¶œë ¥(`1` ë˜ëŠ” `0`) â†’ but ë¹„ì„ í˜•ì  ë¶„ë¥˜ì˜ ì–´ë ¤ì›€ (XOR)
    - **ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ (Multi-Layer Perceptron)** : ì…ë ¥ì¸µê³¼ ì¶œë ¥ì¸µ ì‚¬ì´ì— í•˜ë‚˜ ì´ìƒì˜ ì¤‘ê°„ì¸µ(ì€ë‹‰ì¸µ)ì„ ë‘ëŠ” ë°©ì‹ â†’ ë¹„ì„ í˜•ì  ë¶„ë¥˜ ê°€ëŠ¥
    - **ë”¥ëŸ¬ë‹ = ì‹¬ì¸µ ì‹ ê²½ë§(Deep Neural Network)** : ì€ë‹‰ì¸µì´ ì—¬ëŸ¬ ê°œ ìˆëŠ” ì‹ ê²½ë§
        
        ![image.png](attachment:f85c0dc8-fb79-4fbc-8cde-63f949a5d4d7:image.png)
        
    - ë”¥ëŸ¬ë‹ì˜ ì´ì  : íŠ¹ì„± ì¶”ì¶œ(Feature Extraction - íŒ¨í„´ì´ë‚˜ ê·œì¹™ ì°¾ê¸° â†’ SVM, Naive-Bayes, Logistic Regression íŠ¹ì„± ì¶”ì¶œ ê³¼ì • í†µí•©), ë¹…ë°ì´í„° íš¨ìœ¨ì  í™œìš©
- **ë”¥ëŸ¬ë‹ì˜ êµ¬ì¡°**
    - ğŸ’» Code
        
        ```python
        class Net(torch.nn.Module):
            def __init__(self, n_feature, n_hidden, n_output):
                super(Net, self).__init__()
                self.hidden = torch.nn.Linear(n_feature, n_hidden)  # ì€ë‹‰ì¸µ
                self.relu = torch.nn.ReLU(inplace=True)             # í™œì„±í™” í•¨ìˆ˜
                self.out = torch.nn.Linear(n_hidden, n_output)      # ì¶œë ¥ì¸µ
                self.softmax = torch.nn.Softmax(dim=n_output)        # í™œì„±í™” í•¨ìˆ˜
            def forward(self, x):
                x = self.hidden(x)
                x = self.relu(x)
                x = self.out(x)
                x = self.softmax(x)
                return x
        ```
        
    - 1ï¸âƒ£ **ì…ë ¥ì¸µ(Input Layer)** : ë°ì´í„° ì…ë ¥
    - 2ï¸âƒ£ **ì€ë‹‰ì¸µ(Hidden Layer)** : ê°€ì¤‘í•© ê³„ì‚° â†’ í™œì„±í™” í•¨ìˆ˜ ì ìš© â†’ ì¶œë ¥ì¸µ ì „ë‹¬
        - **ê°€ì¤‘í•© (ì „ë‹¬ í•¨ìˆ˜)** : ì…ë ¥ ê°’ì— ê°€ì¤‘ì¹˜(ì—°ì‚° ê²°ê³¼ ì¡°ì •)ë¥¼ ê³±í•¨ ($\sum_i w_ix_i + b$)
        - **í™œì„±í™” í•¨ìˆ˜** : ë¹„ì„ í˜• í•¨ìˆ˜ë¡œ ì¶œë ¥ ê°’ ë³€í™”
            - *í™œì„±í™” í•¨ìˆ˜ì˜ ì¢…ë¥˜?*
                - **Sigmoid** (0~1) : $sigmoid\ x = \frac{1}{1+e^{-x}}$
                - **Hyperbolic Tangent** (-1~1) : $tanh\ x = \frac{sinh\ x}{cosh\ x} = \frac{e^x - e^{-x}}{e^x + e^{-x}}$
                    
                    â†’ ê¸°ìš¸ê¸° ì†Œë©¸ ë¬¸ì œ (Vanishing Gradient Problem)
                    
                - **ReLU** (ì…ë ¥ì´ ìŒìˆ˜ì¼ ë•Œ 0 ì¶œë ¥, ì–‘ìˆ˜ì¼ ë•Œ ê·¸ëŒ€ë¡œ ì¶œë ¥)
                    
                    â†’ ë¹ ë¥¸ í•™ìŠµ ì†ë„, ê¸°ìš¸ê¸° ì†Œë©¸ ë¬¸ì œ X (ì£¼ë¡œ ì€ë‹‰ì¸µì—ì„œ ì‚¬ìš©)
                    
                - **Leaky ReLU** (ì…ë ¥ì´ ìŒìˆ˜ì¼ ë•Œ ë§¤ìš° ì‘ì€ ìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” ReLU)
                - **Softmax** (0~1, ì¶œë ¥ ê°’ë“¤ì˜ ì´í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”) : $y_k = \frac{e^{a_k}}{\sum_{i=1}^{n}e^{a_i}}$
                    
                    â†’ ì¶œë ¥ ë…¸ë“œì˜ í™œì„±í™” í•¨ìˆ˜
                    
    - 3ï¸âƒ£ **ì¶œë ¥ì¸µ(Output Layer)** : ìµœì¢… ê²°ê³¼ê°’
        - **ì†ì‹¤ í•¨ìˆ˜(Loss Function)** : ì¶œë ¥ í•¨ìˆ˜ì˜ ê²°ê³¼ì™€ ì‹¤ì œ ê°’ ê°„ì˜ ì˜¤ì°¨ë¥¼ ì¸¡ì •
            - *ì†ì‹¤ í•¨ìˆ˜ì˜ ì¢…ë¥˜?*
                - **í‰ê·  ì œê³± ì˜¤ì°¨(Mean Squared Error, MSE)** : $MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y_i})^2$
                    
                    â†’ íšŒê·€
                    
                    `torch.nn.MSELoss(reduction='sum')(ì˜ˆì¸¡, íƒ€ê¹ƒ)`
                    
                - **í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨(Cross Entropy Error, CEE)** : $CrossEntropy=-\sum_{i=1}^{n}y_i\ log\hat{y_i}$
                    
                    â†’ ë¶„ë¥˜ (ì›-í•« ì¸ì½”ë”© ë°©ì‹)
                    
                    `torch.nn.CrossEntropyLoss()(ì˜ˆì¸¡, íƒ€ê¹ƒ)` * ì˜ˆì¸¡ì€ (N, Class ê°œìˆ˜), íƒ€ê¹ƒì€ (N, 1)
                    
    - **ìˆœì „íŒŒ**(FeedForward, ì˜ˆì¸¡ ê°’ ê³„ì‚°) â†’ ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚° â†’ **ì—­ì „íŒŒ**(BackPropagation, ì†ì‹¤ í•¨ìˆ˜ ë¹„ìš©ì´ 0ì— ê°€ê¹Œì›Œì§€ë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •)
        
        ![image.png](attachment:bf287a60-7d32-4a45-a4e3-48b7b702b8d4:image.png)
        
        - *ì†ì‹¤ í•¨ìˆ˜ëŠ” ì˜¤ì°¨ë¥¼ êµ¬í•˜ëŠ” ë°©ë²•, ì—­ì „íŒŒëŠ” ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •!*
        - **ê²½ì‚¬ í•˜ê°•ë²•** : í•™ìŠµë¥ (learning rate)ê³¼ ì†ì‹¤ í•¨ìˆ˜ì˜ ìˆœê°„ ê¸°ìš¸ê¸°(ë¯¸ë¶„ê°’)ë¥¼ ì´ìš©í•´ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
- **ë”¥ëŸ¬ë‹ ì„±ëŠ¥ ë†’ì´ê¸°**
    - **ë¬¸ì œ1. ê³¼ì í•©(Over-Fitting)** : í›ˆë ¨ ë°ì´í„°ë¥¼ ê³¼í•˜ê²Œ í•™ìŠµ (ì‹¤ì œ ë°ì´í„° ì˜¤ì°¨ ì¦ê°€) â†’ *ë‹¨ìˆœíˆ ì€ë‹‰ì¸µ ê°œìˆ˜ê°€ ë§ë‹¤ê³  ì¢‹ì€ ê²Œ ì•„ë‹ˆë‹¤!*
        - **ë“œë¡­ì•„ì›ƒ(Dropout)** : ì‹ ê²½ë§ ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì • ì¤‘ ì¼ë¶€ ë…¸ë“œë“¤ì„ ì„ì˜ë¡œ í•™ìŠµì—ì„œ ì œì™¸ì‹œí‚´ â†’ `torch.nn.Dropout(ì‚¬ìš©í•˜ì§€ ì•Šì„ ë¹„ìœ¨)`
    - **ë¬¸ì œ2. ê¸°ìš¸ê¸° ì†Œë©¸ ë¬¸ì œ ë°œìƒ** : ì¶œë ¥ì¸µ â†’ ì€ë‹‰ì¸µ ì „ë‹¬ ì˜¤ì°¨ê°€ í¬ê²Œ ì¤„ì–´ë“¤ì–´ í•™ìŠµì´ ë˜ì§€ ì•ŠëŠ” í˜„ìƒ
        - ReLU í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš© (Sigmoid, Tanh ëŒ€ì‹ )
    - **ë¬¸ì œ3. ì„±ëŠ¥ì´ ë‚˜ë¹ ì§€ëŠ” ë¬¸ì œ**
        
        ![image.png](attachment:82d4887e-9153-4c03-8c46-b983d2719628:image.png)
        
    - **ë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²• (Batch Gradient Descent, BGD)** : ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚° â†’ ê¸°ìš¸ê¸°ë¥¼ í•œ ë²ˆë§Œ ê³„ì‚°í•˜ì—¬ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ (ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ê°€ì¤‘ì¹˜ í¸ë¯¸ë¶„)
    $W = W-aâ–½J(W,b)$
    - **í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(Stochastic Gradient Descent, SGD)** : ì„ì˜ë¡œ ì„ íƒí•œ ë°ì´í„°ì— ëŒ€í•´ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²• (ë¹ ë¥¸ ê³„ì‚°)
    - **ë¯¸ë‹ˆ ë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²• (Mini-batch Gradient Descent)** : ì „ì²´ ë°ì´í„°ì…‹ì„ ë¯¸ë‹ˆ ë°°ì¹˜ ì—¬ëŸ¬ ê°œë¡œ ë‚˜ëˆ„ê³ , ë¯¸ë‹ˆ ë°°ì¹˜ í•˜ë‚˜ë§ˆë‹¤ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•œ í›„ í‰ê·  ê¸°ìš¸ê¸°ë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ ì—…ë°ì´íŠ¸ (ì•ˆì •ì )
        
        `DataLoader(ë°ì´í„°ì…‹, batch_size=ë¯¸ë‹ˆ ë°°ì¹˜ í¬ê¸°, shuffle=ëœë¤ìœ¼ë¡œ ì„ìœ¼ë©´ True)`
        
        - ğŸ’» Code
            
            ```python
            class CustomDataset(Dataset):
                def __init__(self):
                    self.x_data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
                    self.y_data = [[12], [18], [11]]
                    def __len__(self):
                        return len(self.x_data)
                    def __getitem__(self, idx):
                        x = torch.FloatTensor(self.x_data[idx])
                        y = torch.FloatTensor(self.y_data[idx])
                        return x, y
            dataset = CustomDataset()
            dataloader = DataLoader(
                dataset, # ë°ì´í„°ì…‹
                batch_size=2, # ë¯¸ë‹ˆ ë°°ì¹˜ í¬ê¸°
                shuffle=True, # ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œë§ˆë‹¤ ëœë¤ìœ¼ë¡œ ì„ê¸°
            )
            ```
            
- **ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸í•˜ê¸° - ì˜µí‹°ë§ˆì´ì €**
    - **ì˜µí‹°ë§ˆì´ì €(Optimizer)** : í•™ìŠµ ì†ë„ì™€ ìš´ë™ëŸ‰ì„ ì¡°ì •
        
        ![image.png](attachment:01e94b04-96b9-4a5a-8b72-092c20c7fdd9:image.png)
        
        - **AdaGrad (Adaptive Gradient)** : ê°€ì¤‘ì¹˜ì˜ ì—…ë°ì´íŠ¸ íšŸìˆ˜ì— ë”°ë¼ í•™ìŠµë¥ ì„ ì¡°ì • (ë§ì´ ë³€í™”í•˜ëŠ” ë³€ìˆ˜ë“¤ì˜ í•™ìŠµë¥ ì„ í¬ê²Œ í•¨)
        - **AdaDelta (Adaptive Delta)** : AdaGradì—ì„œ í•™ìŠµì´ ë©ˆì¶”ëŠ” ë¬¸ì œ í•´ê²°
        - **RMSProp** : AdaGradì—ì„œ í•™ìŠµë¥ ì´ ì‘ì•„ì§€ëŠ” ë¬¸ì œ í•´ê²°
        - **Momentum** : ê°€ì¤‘ì¹˜ë¥¼ ìˆ˜ì •í•˜ê¸° ì „ì— ì´ì „ ìˆ˜ì • ë°©í–¥ì„ ì°¸ê³ í•˜ì—¬ ê°™ì€ ë°©í–¥ìœ¼ë¡œ ì¼ì •í•œ ë¹„ìœ¨ë§Œ ìˆ˜ì • (ê´€ì„± íš¨ê³¼) â†’ SGDì™€ í•¨ê»˜ ì‚¬ìš©
        - **Nesterov Accelerated Gradient (NAG)** : ëª¨ë©˜í…€ ê°’ì´ ì ìš©ëœ ì§€ì ì—ì„œ ê¸°ìš¸ê¸° ê°’ ê³„ì‚°
        - **Adam (Adaptive Moment Estimation)** : Momentum + RMSProp ì¥ì  ê²°í•©
            - ğŸ’» Code
                
                ```python
                optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)
                optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0) # ê¸°ë³¸ê°’ 1.0
                optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01) # ê¸°ë³¸ê°’ 1e-2
                optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # momentum ì¦ê°€ì‹œí‚¤ë©° ì‚¬ìš©
                optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True) # nesterov ê¸°ë³¸ê°’ False
                optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # ê¸°ë³¸ê°’ 1e-3
                ```
                

### **ğŸ“Œ 4.3. ~ 4.4. ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ / ìš°ë¦¬ëŠ” ë¬´ì—‡ì„ ë°°ì›Œì•¼ í• ê¹Œ?**

- **ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜**
    - **ì‹¬ì¸µ ì‹ ê²½ë§(DNN)** : ì…ë ¥ì¸µê³¼ ì¶œë ¥ì¸µ ì‚¬ì´ì— ë‹¤ìˆ˜ì˜ ì€ë‹‰ì¸µì„ í¬í•¨í•˜ëŠ” ì¸ê³µ ì‹ ê²½ë§
        
        â†’ ë§ì€ ì—°ì‚°ëŸ‰, ê¸°ìš¸ê¸° ì†Œë©¸ ë¬¸ì œ (ë“œë¡­ì•„ì›ƒ, ë ë£¨ í•¨ìˆ˜, ë°°ì¹˜ ì •ê·œí™” ì ìš©ìœ¼ë¡œ í•´ê²°)
        
    - **í•©ì„±ê³± ì‹ ê²½ë§(Convolutional Neural Network)** : í•©ì„±ê³±ì¸µ(Convolutional Layer)ê³¼ í’€ë§ì¸µ(Pooling Layer) í¬í•¨, ì´ë¯¸ì§€ ì²˜ë¦¬ ì„±ëŠ¥ì´ ì¢‹ì€ ì¸ê³µ ì‹ ê²½ë§
        
        â†’ LeNet-5, AlexNet, VGG, GoogLeNet, ResNet
        
    - **ìˆœí™˜ ì‹ ê²½ë§(Recurrent Neural Network)** : ì‹œê³„ì—´ ë°ì´í„°(ì‹œê°„ì„± ì •ë³´) ê°™ì´ ì‹œê°„ íë¦„ì— ë”°ë¼ ë³€í™”í•˜ëŠ” ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•œ ì¸ê³µ ì‹ ê²½ë§ (ë™ì ì´ê³  ê¸¸ì´ê°€ ê°€ë³€ì ì¸ ë°ì´í„°)
        
        â†’ ê¸°ìš¸ê¸° ì†Œë©¸ ë¬¸ì œ (LSTMìœ¼ë¡œ ë©”ëª¨ë¦¬ ê°œë… ë„ì…)
        
    - **ì œí•œëœ ë³¼ì¸ ë§Œ ë¨¸ì‹ (Restricted Boltzmann Machine)** : ê°€ì‹œì¸µ(Visible Layer)ê³¼ ì€ë‹‰ì¸µ(Hidden Layer)ë¡œ êµ¬ì„±ëœ ëª¨ë¸ (ê°€ì‹œì¸µì€ ì€ë‹‰ì¸µê³¼ë§Œ ì—°ê²°)
        
        â†’ ì°¨ì› ê°ì†Œ, ë¶„ë¥˜, ì„ í˜• íšŒê·€ ë¶„ì„, í˜‘ì—… í•„í„°ë§, íŠ¹ì„± ê°’ í•™ìŠµ, ì£¼ì œ ëª¨ë¸ë§ / ì‚¬ì „ í•™ìŠµ ìš©ë„
        
    - **ì‹¬ì¸µ ì‹ ë¢° ì‹ ê²½ë§(Deep Belief Network)** : ì œí•œëœ ë³¼ì¸ ë§Œ ë¨¸ì‹ ì„ ì—¬ëŸ¬ ì¸µìœ¼ë¡œ ìŒ“ì€ í˜•íƒœë¡œ ì—°ê²°ëœ ì‹ ê²½ë§
        
        â†’ ë¹„ì§€ë„ í•™ìŠµ ê°€ëŠ¥ (ì œí•œëœ ë³¼ì¸ ë§Œ ë¨¸ì‹  ì‚¬ì „ í›ˆë ¨ â†’ ìˆœì°¨ì  í•™ìŠµìœ¼ë¡œ ê³„ì¸µì  êµ¬ì¡° ìƒì„±)
        

### **ğŸ“Œ 5.1. ~ 5.2. í•©ì„±ê³± ì‹ ê²½ë§ / í•©ì„±ê³± ì‹ ê²½ë§ ë§›ë³´ê¸°**

- **í•©ì„±ê³± ì‹ ê²½ë§ì˜ ì •ì˜**
    - **í•©ì„±ê³± ì‹ ê²½ë§(CNN)** : ìŒì„± ì¸ì‹, ì´ë¯¸ì§€/ì˜ìƒ ì¸ì‹ì— ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì‹ ê²½ë§ (ë‹¤ì°¨ì› ë°°ì—´ ì²˜ë¦¬ íŠ¹í™”) â†’ ë°ì´í„°ì˜ ê³µê°„ì  êµ¬ì¡°ê¹Œì§€ í™œìš©!
- **í•©ì„±ê³± ì‹ ê²½ë§ì˜ êµ¬ì¡°**
    - 1ï¸âƒ£ **ì…ë ¥ì¸µ(Input Layer)** : ì…ë ¥ ë°ì´í„°ëŠ” (ë†’ì´, ë„ˆë¹„, ì±„ë„) ê°’ì„ ê°–ëŠ” 3ì°¨ì› ë°ì´í„°
        - ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì´ë©´ ì±„ë„ `1`, ì»¬ëŸ¬(RGB)ë©´ ì±„ë„ `3`
    - 2ï¸âƒ£ **í•©ì„±ê³±ì¸µ(Convolutional Layer)** : ì…ë ¥ ë°ì´í„°ì—ì„œ íŠ¹ì„± ì¶”ì¶œ
        - **ì»¤ë„(Kernel) = í•„í„°** : ìŠ¤íŠ¸ë¼ì´ë“œ(Stride, ê°„ê²©)ì— ë”°ë¼ ì´ë™í•˜ë©° ì´ë¯¸ì§€ì˜ ëª¨ë“  ì˜ì—­ì„ í›‘ê³  íŠ¹ì„±ì„ ì¶”ì¶œí•¨ (ì£¼ë¡œ 3x3, 5x5 ì»¤ë„ ì‚¬ìš©) â†’ **íŠ¹ì„± ë§µ(Feature Map)**
        - **íŒ¨ë”©** : ì…ë ¥ ë°ì´í„° ì£¼ìœ„ë¥¼ 0ìœ¼ë¡œ ì±„ì›€
        - ì…ë ¥ ê°’ì˜ ì±„ë„ì´ 1ì´ ì•„ë‹Œ ê²½ìš° : ê° ì±„ë„(RGB ê°ê°)ì— ì„œë¡œ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¡œ í•©ì„±ê³±ì„ ì ìš© í›„ ê²°ê³¼ë¥¼ ë”í•¨
        - 2ê°œ ì´ìƒì˜ í•„í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° : í•„í„° ê°ê°ì´ íŠ¹ì„± ë§µì˜ ì±„ë„ì´ ë¨
        - ì¶œë ¥ ë°ì´í„°ì˜ í¬ê¸° : (W, H, D) â†’ $(\frac{W-F+2P}{S}+1, \frac{H-F+2P}{S}+1, K)$
            - í•„í„° ê°œìˆ˜ K, í•„í„° í¬ê¸° F, ìŠ¤íŠ¸ë¼ì´ë“œ S, íŒ¨ë”© P
    - 3ï¸âƒ£ **í’€ë§ì¸µ(Pooling Layer)** : íŠ¹ì„± ë§µì˜ ì°¨ì›ì„ ë‹¤ìš´ ìƒ˜í”Œë§í•˜ì—¬ ì—°ì‚°ëŸ‰ ê°ì†Œ
        - ìµœëŒ€ í’€ë§(Max Pooling), í‰ê·  í’€ë§(Average Pooling), ìµœì†Œ í’€ë§
        - **`MaxPool2d`** : ì¶œë ¥ ë°ì´í„° í¬ê¸° ì¶•ì†Œ, íŠ¹ì • ë°ì´í„° ê°•ì¡°
        - í•©ì„±ê³±ì¸µ + í’€ë§ì¸µ â†’ ì…ë ¥ ì´ë¯¸ì§€ì˜ ì£¼ìš” íŠ¹ì„± ë²¡í„°(Feature Vector) ì¶”ì¶œ
    - 4ï¸âƒ£ **ì™„ì „ì—°ê²°ì¸µ(Fully Connected Layer)** : Flatten - 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
    - 5ï¸âƒ£ **ì¶œë ¥ì¸µ (Output Layer)** : í™œì„±í™” í•¨ìˆ˜(Softmax)ì˜ ìµœì¢… ê²°ê³¼ ì¶œë ¥ (ê° ë ˆì´ë¸”ì— ì†í•  í™•ë¥ )
        - ë°ì´í„°ë¥¼ ë°°ì—´ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì‘ì—…, í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì— ë”°ë¼ ì¶œë ¥ í¬ê¸° ë‹¬ë¼ì§
- **í•©ì„±ê³± ì°¨ì›** â† í•„í„°ì˜ ì´ë™ ë°©í–¥ ìˆ˜, ì¶œë ¥ í˜•íƒœì— ë”°ë¼
    
    ![image.png](attachment:c9eeb7be-701f-4bb5-b8d2-a11c78ec0cf2:image.png)
    
    - **1D í•©ì„±ê³±** : 1ê°œ ë°©í–¥ ì›€ì§ì„ (ì‹œê°„ ì¶•ìœ¼ë¡œ ì¢Œìš° ì´ë™) `W x (k, k) â†’ W`
    - **2D í•©ì„±ê³±** : 2ê°œ ë°©í–¥ ì›€ì§ì„ `(W, H) x (k, k) â†’ (W, H)`
    - **3D í•©ì„±ê³±** : 3ê°œ ë°©í–¥ ì›€ì§ì„ `(W, H, L) x (k, k, d) â†’ (W, H, L) (d < L)`
        - 3D ì…ë ¥ì„ ê°–ëŠ” 2D í•©ì„±ê³± `(W, H, L) x (k, k, L) â†’ (W, H)` (LeNet-5, VGG)
        - 1x1xL í•„í„° : ì—°ì‚°ëŸ‰ì„ ê°ì†Œ (ê¹Šì´ ì—†ì•°)
    - **BatchNorm2d** : ê° ë°°ì¹˜ ë‹¨ìœ„ë³„ë¡œ ë°ì´í„°ê°€ ë‹¤ì–‘í•œ ë¶„í¬ë¥¼ ê°€ì§€ë”ë¼ë„ í‰ê· ê³¼ ë¶„ì‚°ì„ ì´ìš©í•˜ì—¬ ì •ê·œí™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë°ì´í„° ë¶„í¬ ì¡°ì •)
    - ğŸ’» Code
        
        ```python
        import numpy as np
        import matplotlib.pyplot as plt
        
        import torch
        import torch.nn as nn  # ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ì„±
        from torch.autograd import Variable
        import torch.nn.functional as F
        
        import torchvision
        import torchvision.transforms as transforms # ë°ì´í„° ì „ì²˜ë¦¬
        from torch.utils.data import Dataset, DataLoader
        
        from google.colab import drive
        drive.mount("/content/drive")
        
        import os
        os.chdir("drive/MyDrive/í”„ë¡œë©”í…Œìš°ìŠ¤ ìŠ¤í„°ë””")
        
        # GPU ì„¤ì •
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        
        # ë°ì´í„° ë¡œë“œ
        train_dataset = torchvision.datasets.FashionMNIST("chap05/data", download=True,
                               transform=transforms.Compose([transforms.ToTensor()]))
        test_dataset = torchvision.datasets.FashionMNIST("chap05/data", download=True,
                        train=False, transform=transforms.Compose([transforms.ToTensor()]))
        
        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100)
        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100)
        
        labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat',
                      5 : 'Sandal', 6 : 'Shirt', 7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'}
        
        # ë°ì´í„° í™•ì¸í•˜ê¸°
        fig = plt.figure(figsize=(8,8));
        columns = 4;
        rows = 5;
        for i in range(1, columns*rows +1):
            img_xy = np.random.randint(len(train_dataset))
            img = train_dataset[img_xy][0][0,:,:]
            fig.add_subplot(rows, columns, i)
            plt.title(labels_map[train_dataset[img_xy][1]])
            plt.axis('off')
            plt.imshow(img, cmap='gray')
        plt.show()
        
        # ëª¨ë¸1
        class FashionDNN(nn.Module):
            def __init__(self):  # ì†ì„±ê°’ ì´ˆê¸°í™” (ê°ì²´ ìƒì„±ê³¼ í•¨ê»˜ í˜¸ì¶œ)
                super(FashionDNN, self).__init__()  # ë¶€ëª¨ í´ë˜ìŠ¤ ìƒì†
                self.fc1 = nn.Linear(in_features=784, out_features=256)  # ì„ í˜• íšŒê·€ ëª¨ë¸
                self.drop = nn.Dropout(0.25)
                self.fc2 = nn.Linear(in_features=256, out_features=128)
                self.fc3 = nn.Linear(in_features=128, out_features=10)
        
            def forward(self, input_data):  # ìˆœì „íŒŒ í•™ìŠµ ì§„í–‰
                out = input_data.view(-1, 784)
                out = F.relu(self.fc1(out))
                out = self.drop(out)
                out = F.relu(self.fc2(out))
                out = self.fc3(out)
                return out
                
        # ëª¨ë¸2
        class FashionCNN(nn.Module):
            def __init__(self):
                super(FashionCNN, self).__init__()
                self.layer1 = nn.Sequential(  # nn.Sequential : ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ ì •ì˜
                    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),  # ì±„ë„ = ê¹Šì´
                    nn.BatchNorm2d(32),
                    nn.ReLU(),
                    nn.MaxPool2d(kernel_size=2, stride=2)
                )
                self.layer2 = nn.Sequential(
                    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),
                    nn.BatchNorm2d(64),
                    nn.ReLU(),
                    nn.MaxPool2d(2)
                )
                self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)
                self.drop = nn.Dropout2d(0.25)
                self.fc2 = nn.Linear(in_features=600, out_features=120)
                self.fc3 = nn.Linear(in_features=120, out_features=10)  # ë§ˆì§€ë§‰ ê³„ì¸µì˜ out_features = í´ë˜ìŠ¤ ê°œìˆ˜
        
            def forward(self, x):
                out = self.layer1(x)
                out = self.layer2(out)
                out = out.view(out.size(0), -1)
                out = self.fc1(out)
                out = self.drop(out)
                out = self.fc2(out)
                out = self.fc3(out)
                return out         
        
        # ì†ì‹¤ í•¨ìˆ˜, í•™ìŠµë¥ , ì˜µí‹°ë§ˆì´ì € ì •ì˜
        learning_rate = 0.001
        model = FashionCNN()
        model.to(device)
        
        criterion = nn.CrossEntropyLoss()  # ë¶„ë¥˜ ë¬¸ì œ ì†ì‹¤ í•¨ìˆ˜
        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
        print(model)
        
        # ëª¨ë¸ í•™ìŠµ
        num_epochs = 5
        count = 0
        loss_list = []
        iteration_list = []
        accuracy_list = []
        
        predictions_list = []
        labels_list = []
        
        for epoch in range(num_epochs):
            for images, labels in train_loader:
                images, labels = images.to(device), labels.to(device)
        
                # torch.autograd.Variable ì´ìš©í•´ ì—­ì „íŒŒë¥¼ ìœ„í•œ ë¯¸ë¶„ ê°’ ìë™ ê³„ì‚°
                train = Variable(images.view(100, 1, 28, 28))
                labels = Variable(labels)
        
                outputs = model(train)  # í•™ìŠµ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì ìš©
                loss = criterion(outputs, labels)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                count += 1
        
                if not (count % 50):
                    total = 0
                    correct = 0
                    for images, labels in test_loader:
                        images, labels = images.to(device), labels.to(device)  # GPU ì‚¬ìš©
                        labels_list.append(labels)
                        test = Variable(images.view(100, 1, 28, 28))
                        outputs = model(test)
                        predictions = torch.max(outputs, 1)[1].to(device)
                        predictions_list.append(predictions)
                        correct += (predictions == labels).sum()
                        total += len(labels)
        
                    accuracy = correct * 100 / total # ì •í™•ë„
                    loss_list.append(loss.data)
                    iteration_list.append(count)
                    accuracy_list.append(accuracy)
        
                if not (count % 500):
                    print("Iteration: {}, Loss: {}, Accuracy: {}%".format(count, loss.data, accuracy))
        ```
        
- ğŸ’» **ì½”ë“œ ì´í•´í•˜ê¸°**
    - GPU ì‚¬ìš©
        
        ```python
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = Net()
        if torch.cuda.device_count() > 1:  # ë‹¤ìˆ˜ì˜ GPU ì‚¬ìš©
            model = nn.DataParallel(net)  # ë°°ì¹˜ í¬ê¸°ê°€ ì•Œì•„ì„œ ê° GPUë¡œ ë¶„ë°°
        model.to(device)
        ```
        
    - ë°ì´í„°ì…‹
        - `fashion_mnist` ë°ì´í„°ì…‹ : 28x28 í”½ì…€ ì´ë¯¸ì§€ 7ë§Œ ê°œ
        - `train_images` ë„˜íŒŒì´ ë°°ì—´
        - `train_labels` 0~9 ì •ìˆ˜ ê°’ â†’ ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ ë ˆì´ë¸”
        - ì…ë ¥ê°’ : (N, 1, 28, 28) í˜•íƒœ â†’ ì´ë¯¸ì§€ í…ì„œì™€ ì •ìˆ˜í˜• ë ˆì´ë¸” íŠœí”Œ
        - `torchvision.datasets.ë°ì´í„°ì´ë¦„("ë‚´ë ¤ë°›ì„ ìœ„ì¹˜", download=True, transform=transforms.Compose([transforms.ToTensor()]))`
        - `torch.utils.data.DataLoader(ë°ì´í„°ì…‹, batch_size=ë°°ì¹˜ í¬ê¸°)`  : ë°°ì¹˜ í¬ê¸° ë‹¨ìœ„ë¡œ ë°ì´í„° ë¬¶ì–´ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
    - ëœë¤ê°’ ë°›ê¸°
        - `np.random.randint(ì‹œì‘, ë+1)`
        - `np.random.randint(ë)` : 0~ë
        - `np.random.rand(í–‰ë ¬ í¬ê¸°)` : 0~1 ì‚¬ì´ í‘œì¤€ì •ê·œë¶„í¬
        - `np.random.randn(í–‰ë ¬ í¬ê¸°)` : í‰ê·  0, í‘œì¤€í¸ì°¨ 1 ê°€ìš°ì‹œì•ˆ ì •ê·œë¶„í¬ ë‚œìˆ˜
        - `np.arange(ì‹œì‘, ë+1, ê±´ë„ˆë›°ê¸°)`
    - ëª¨ë¸ : `torch.nn.Module` ìƒì†
        - `nn.Linear(in_features=ì…ë ¥ í¬ê¸°, out_features=ì¶œë ¥ í¬ê¸°)`
        - `nn.Dropout(ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨)` ë¹„ìœ¨ë§Œí¼ í…ì„œì˜ ê°’ì´ 0ì´ ë˜ê³ , 0ì´ ë˜ì§€ ì•ŠëŠ” ê°’ì€ 1/(1-p)ë°°
    - í™œì„±í™” í•¨ìˆ˜ (ë‘ ê°€ì§€ ë°©ë²•)
        - `F.relu()`  â†’ `forward()` í•¨ìˆ˜
        - `nn.ReLU()` â†’ `__init__()` í•¨ìˆ˜
    - `torch.nn` vs. `torch.nn.functional`
        - ğŸ’» Code
            
            ```python
            
            # torch.nn.xx
            inputs = torch.randn(64, 3, 244, 244)
            conv = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)
            outputs = conv(inputs)
            layer = nn.Conv2d(1, 1, 3)
            
            #-------------
            
            # nn.functional.xx
            import torch.nn.functional as F
            inputs = torch.randn(64, 3, 244, 244)
            weight = torch.randn(64, 3, 3, 3)
            bias = torch.randn(64)
            # ì…ë ¥ê³¼ ê°€ì¤‘ì¹˜ ìì²´ ë„£ê¸°
            outputs = F.conv2d(inputs, weight, bias, padding=1)
            ```
            
        
        | **torch.nn** | **torch.nn.functional** |
        | --- | --- |
        | í´ë˜ìŠ¤ ì‚¬ìš© | í•¨ìˆ˜ ì‚¬ìš© |
        | í•˜ì´í¼íŒŒë¼ë¯¸í„° ì „ë‹¬ í›„ í•¨ìˆ˜ í˜¸ì¶œì„
        í†µí•´ ë°ì´í„° ì „ë‹¬ | í•¨ìˆ˜ í˜¸ì¶œí•  ë•Œ í•˜ì´í¼íŒŒë¼ë¯¸í„°,
        ë°ì´í„° ì „ë‹¬ |
        | nn.Sequential ë‚´ì— ìœ„ì¹˜ | nn.Sequential ë‚´ì— ìœ„ì¹˜ ë¶ˆê°€ |
        | íŒŒë¼ë¯¸í„° ìƒˆë¡œ ì •ì˜í•  í•„ìš” ì—†ìŒ | ê°€ì¤‘ì¹˜ ì „ë‹¬í•  ë•Œë§ˆë‹¤ ê°€ì¤‘ì¹˜
        ê°’ì„ ìƒˆë¡œ ì •ì˜ |

### **ğŸ“Œ 5.3. ~ 5.5. ì „ì´ í•™ìŠµ / ì„¤ëª… ê°€ëŠ¥í•œ CNN / ê·¸ë˜í”„ í•©ì„±ê³± ë„¤íŠ¸ì›Œí¬**

- **ì „ì´ í•™ìŠµì˜ ì •ì˜**
    - **ì „ì´ í•™ìŠµ (Transfer Learning)** : ì•„ì£¼ í° ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸(ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸)ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì™€ í•´ê²°í•˜ëŠ” ê³¼ì œì— ë§ê²Œ ë³´ì •í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒ
        - í•©ì„±ê³±ì¸µ(í•©ì„±ê³±ì¸µ + í’€ë§ì¸µ) + ì™„ì „ì—°ê²°ì¸µ(ë°ì´í„° ë¶„ë¥˜ê¸°)
    - **íŠ¹ì„± ì¶”ì¶œ(Feature Extractor)** : ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ â†’ ë§ˆì§€ë§‰ ì™„ì „ì—°ê²°ì¸µ ë¶€ë¶„ë§Œ ìƒˆë¡œ í•™ìŠµ (ë‚˜ë¨¸ì§€ ê³„ì¸µ ê°€ì¤‘ì¹˜ ê³ ì •)
        
        ![image.png](attachment:6fa2cde5-372e-42cc-a06d-324b44b8e0ac:image.png)
        
    - **ë¯¸ì„¸ ì¡°ì • ê¸°ë²•(Fine-Tuning)** : ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸, í•©ì„±ê³±ì¸µ, ì™„ì „ì—°ê²°ì¸µì˜ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸í•˜ì—¬ í›ˆë ¨
    - ëª¨ë¸
        
        ```python
        import torchvision.models as models  # ë¬´ì‘ìœ„ ê°€ì¤‘ì¹˜ ëª¨ë¸
        resnet18 = models.resnet18()
        alexnet = models.alexnet()
        vgg16 = models.vgg16()
        squeezenet = models.squeezenet1_0()
        densenet = models.densenet161()
        inception = models.inception_v3()
        googlenet = models.googlenet()
        shufflenet = models.shufflenet_v2_x1_0()
        mobilenet_v2 = models.mobilenet_v2()
        mobilenet_v3_large = models.mobilenet_v3_large()
        mobilenet_v3_small = models.mobilenet_v3_small()
        resnext50_32x4d = models.resnext50_32x4d()
        wide_resnet50_2 = models.wide_resnet50_2()
        mnasnet = models.mnasnet1_0()
        
        import torchvision.models as models  # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸
        resnet18 = models.resnet18(pretrained=True)
        alexnet = models.alexnet(pretrained=True)
        squeezenet = models.squeezenet1_0(pretrained=True)
        vgg16 = models.vgg16(pretrained=True)
        densenet = models.densenet161(pretrained=True) 
        inception = models.inception_v3(pretrained=True)
        googlenet = models.googlenet(pretrained=True)
        shufflenet = models.shufflenet_v2_x1_0(pretrained=True)
        mobilenet_v2 = models.mobilenet_v2(pretrained=True)
        mobilenet_v3_large = models.mobilenet_v3_large(pretrained=True)
        mobilenet_v3_small = models.mobilenet_v3_small(pretrained=True)
        resnext50_32x4d = models.resnext50_32x4d(pretrained=True)
        wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)
        mnasnet = models.mnasnet1_0(pretrained=True)
        ```
        
- **ë¯¸ì„¸ ì¡°ì • ê¸°ë²•**
    - ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ëª©ì ì— ë§ê²Œ ì¬í•™ìŠµ í˜¹ì€ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì¼ë¶€ ì¬í•™ìŠµ
        
        
        | ì¬í•™ìŠµí•  ë¶€ë¶„ | **ë°ì´í„°ì…‹ å¤§** | **ë°ì´í„°ì…‹ å°** |
        | --- | --- | --- |
        | **ìœ ì‚¬ì„± å¤§** | í•©ì„±ê³±ì¸µ ë’·ë¶€ë¶„ + ì™„ì „ì—°ê²°ì¸µ | ì™„ì „ì—°ê²°ì¸µ (ê³¼ì í•© ì¡°ì‹¬) |
        | **ìœ ì‚¬ì„± å°** | ëª¨ë¸ ì „ì²´ ì¬í•™ìŠµ(â€¦) | í•©ì„±ê³±ì¸µ ì¼ë¶€ë¶„ + ì™„ì „ì—°ê²°ì¸µ |
    - ğŸ’» Code
        
        ResNet18 : 50ê°œì˜ ê³„ì¸µìœ¼ë¡œ êµ¬ì„±ëœ CNN, ImageNet ë°ì´í„°ë² ì´ìŠ¤ ì˜ìƒ ì´ìš©í•˜ì—¬ í›ˆë ¨
        
        ```python
        !pip install opencv-python
        
        import os
        import time
        import copy
        import glob
        import cv2  # ë¼ì´ë¸ŒëŸ¬ë¦¬
        import shutil
        
        import torch
        import torchvision  # ì»´í“¨í„° ë¹„ì „(computer vision) ìš©ë„ì˜ íŒ¨í‚¤ì§€
        import torchvision.transforms as transforms  # ë°ì´í„° ì „ì²˜ë¦¬ íŒ¨í‚¤ì§€
        import torchvision.models as models  # íŒŒì´í† ì¹˜ ë„¤íŠ¸ì›Œí¬ íŒ¨í‚¤ì§€
        import torch.nn as nn
        import torch.optim as optim
        from torch.utils.data import DataLoader
        
        import matplotlib.pyplot as plt
        
        from google.colab import drive
        drive.mount("/content/drive")
        
        import os
        os.chdir("drive/MyDrive/í”„ë¡œë©”í…Œìš°ìŠ¤ ìŠ¤í„°ë””")
        
        # ë°ì´í„° ë°›ì•„ì˜¤ê¸°
        data_path = 'chap05/data/catanddog/train'
        
        transform = transforms.Compose([
                        transforms.Resize([256, 256]),  # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
                        transforms.RandomResizedCrop(224),  # ì´ë¯¸ì§€ë¥¼ ëœë¤í•œ í¬ê¸° ë° ë¹„ìœ¨ë¡œ ìë¥´ê¸° (ë°ì´í„° í™•ì¥ ìš©ë„)
                        transforms.RandomHorizontalFlip(),  # ëœë¤í•˜ê²Œ ìˆ˜í‰ìœ¼ë¡œ ë’¤ì§‘ê¸°
                        transforms.ToTensor()
        ])
        train_dataset = torchvision.datasets.ImageFolder(
                        data_path,  # ë¶ˆëŸ¬ì˜¬ ëŒ€ìƒ(ê²½ë¡œ)
                        transform=transform  # ë¶ˆëŸ¬ì˜¬ ë°©ë²•
        )
        train_loader = torch.utils.data.DataLoader(
                       train_dataset,
                       batch_size=32,  # í•œ ë²ˆì— ë¶ˆëŸ¬ì˜¬ ë°ì´í„° ì–‘
                       #  num_workers=8,  # í•˜ìœ„ í”„ë¡œì„¸ìŠ¤ ê°œìˆ˜ (ë°ì´í„° ë¶ˆëŸ¬ì˜¬ ë•Œ)
                       shuffle=True  # ë°ì´í„° ë¬´ì‘ìœ„ë¡œ ì„ê¸°
        )
        print(len(train_dataset))
        
        # ë°ì´í„° ì¶œë ¥í•´ë³´ê¸°
        samples, labels = next(iter(train_loader))
        classes = {0:'cat', 1:'dog'}  # ë ˆì´ë¸”
        fig = plt.figure(figsize=(16,24))
        for i in range(24):  # 24ê°œ ì´ë¯¸ì§€
            a = fig.add_subplot(4,6,i+1)
            a.set_title(classes[labels[i].item()])  # ë ˆì´ë¸” ì •ë³´(í´ë˜ìŠ¤) í•¨ê»˜ ì¶œë ¥
            a.axis('off')
            a.imshow(np.transpose(samples[i].numpy(), (1,2,0)))  # í–‰ë ¬ ì°¨ì› ë°”ê¾¸ê¸°
        plt.subplots_adjust(bottom=0.2, top=0.6, hspace=0)
        
        # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸
        model = models.resnet18(pretrained=True)  # pretrained=True : ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©
        
        for name, param in model.named_parameters():  # ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°’
            if param.requires_grad:
                print(name, param.data)
        
        # ì™„ì „ì—°ê²°ì¸µ
        model.fc = nn.Linear(512, 2)  # 2ê°œ í´ë˜ìŠ¤
        
        for param in model.parameters():  # í•©ì„±ê³±ì¸µ ê°€ì¤‘ì¹˜ ê³ ì •
            param.requires_grad = False  # ì—­ì „íŒŒ ì¤‘ íŒŒë¼ë¯¸í„° ë³€í™” ê³„ì‚° X
        
        for param in model.fc.parameters():  # ì™„ì „ì—°ê²°ì¸µ í•™ìŠµ
            param.requires_grad = True
        
        optimizer = torch.optim.Adam(model.fc.parameters())
        cost = torch.nn.CrossEntropyLoss()  # ì†ì‹¤ í•¨ìˆ˜
        print(model)
        
        # ëª¨ë¸ í›ˆë ¨
        def train_model(model, dataloaders, criterion, optimizer, device, num_epochs=13, is_train=True):
            since = time.time()  # ì»´í“¨í„°ì˜ í˜„ì¬ ì‹œê°
            acc_history = []
            loss_history = []
            best_acc = 0.0
        
            for epoch in range(num_epochs):  # ì—í¬í¬ë§Œí¼ ë°˜ë³µ
                print('Epoch {}/{}'.format(epoch, num_epochs-1))
                print('-' * 10)
        
                running_loss = 0.0
                running_corrects = 0
        
                for inputs, labels in dataloaders:  # ë°ì´í„°ë¡œë”ì— ì „ë‹¬ëœ ë°ì´í„°ë§Œí¼ ë°˜ë³µ
                    inputs = inputs.to(device)
                    labels = labels.to(device)
        
                    model.to(device)
                    optimizer.zero_grad()  # ê¸°ìš¸ê¸°ë¥¼ 0ìœ¼ë¡œ ì„¤ì •
                    outputs = model(inputs)  # ìˆœì „íŒŒ í•™ìŠµ
                    loss = criterion(outputs, labels)
                    _, preds = torch.max(outputs, 1)
                    loss.backward()  # ì—­ì „íŒŒ í•™ìŠµ
                    optimizer.step()
        
                    running_loss += loss.item() * inputs.size(0)  # ì¶œë ¥ ê²°ê³¼ì™€ ë ˆì´ë¸”ì˜ ì˜¤ì°¨ ëˆ„ì 
                    running_corrects += torch.sum(preds == labels.data)  # ì¶œë ¥ ê²°ê³¼ì™€ ë ˆì´ë¸”ì´ ë™ì¼í•œì§€ í™•ì¸í•œ ê²°ê³¼ ëˆ„ì 
        
                epoch_loss = running_loss / len(dataloaders.dataset)  # í‰ê·  ì˜¤ì°¨
                epoch_acc = running_corrects.double() / len(dataloaders.dataset)  # í‰ê·  ì •í™•ë„
        
                print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))
        
                if epoch_acc > best_acc:
                   best_acc = epoch_acc
        
                acc_history.append(epoch_acc.item())
                loss_history.append(epoch_loss)
                torch.save(model.state_dict(), os.path.join('chap05/data/catanddog/',  '{0:0=2d}.pth'.format(epoch)))
                print()
        
            time_elapsed = time.time() - since # ì‹¤í–‰ ì‹œê°„(í•™ìŠµ ì‹œê°„)
            print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
            print('Best Acc: {:4f}'.format(best_acc))
            return acc_history, loss_history  # ì •í™•ë„, ì˜¤ì°¨
        
        params_to_update = []
        for name, param in model.named_parameters():
            if param.requires_grad == True:
                params_to_update.append(param)  # íŒŒë¼ë¯¸í„° í•™ìŠµ ê²°ê³¼ ì €ì¥
                print("\t", name)
        
        optimizer = optim.Adam(params_to_update)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        criterion = nn.CrossEntropyLoss()
        train_acc_hist, train_loss_hist = train_model(model, train_loader, criterion, optimizer, device)
        
        # -----------------------------------------------------------------------------
        
        test_path = 'chap05/data/catanddog/test'
        
        transform = transforms.Compose([
                        transforms.Resize(224),
                        transforms.CenterCrop(224),
                        transforms.ToTensor(),
        ])
        test_dataset = torchvision.datasets.ImageFolder(
            root=test_path,
            transform=transform
        )
        test_loader = torch.utils.data.DataLoader(
            test_dataset,
            batch_size=32,
            num_workers=1,
            shuffle=True
        )
        
        print(len(test_dataset))
        
        def eval_model(model, dataloaders, device):
            since = time.time()
            acc_history = []
            best_acc = 0.0
        
            saved_models = glob.glob('chap05/data/catanddog/' + '*.pth')  # ì›í•˜ëŠ” íŒŒì¼ ì¶”ì¶œ
            saved_models.sort()
            # print('saved_model', saved_models)
        
            for model_path in saved_models:
                print('Loading model', model_path)
        
                model.load_state_dict(torch.load(model_path))
                model.eval()
                model.to(device)
                running_corrects = 0
        
                for inputs, labels in dataloaders:  # í…ŒìŠ¤íŠ¸ ë°˜ë³µ
                    inputs = inputs.to(device)
                    labels = labels.to(device)
        
                    with torch.no_grad():  # autograd ì‚¬ìš© X
                         outputs = model(inputs)
        
                    _, preds = torch.max(outputs.data, 1)  # ë°°ì—´ì˜ ìµœëŒ“ê°’ì´ ë“¤ì–´ ìˆëŠ” ì¸ë±ìŠ¤
                    preds[preds >= 0.5] = 1  # >= 0.5 : ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡
                    preds[preds < 0.5] = 0  # < 0.5 : í‹€ë¦¬ê²Œ ì˜ˆì¸¡
                    running_corrects += preds.eq(labels).int().sum()
        
                epoch_acc = running_corrects.double() / len(dataloaders.dataset)  # ì •í™•ë„ ê³„ì‚°
                print('Acc: {:.4f}'.format(epoch_acc))
        
                if epoch_acc > best_acc:
                    best_acc = epoch_acc
                    acc_history.append(epoch_acc.item())
                    print()
        
                time_elapsed = time.time() - since
                print('Validation complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
                print('Best Acc: {:4f}'.format(best_acc))
        
                return acc_history  # ê³„ì‚°ëœ ì •í™•ë„
        
        val_acc_hist = eval_model(model, test_loader, device)
        
        plt.plot(train_acc_hist)
        plt.plot(val_acc_hist)
        plt.show()
        plt.plot(train_loss_hist)
        plt.show()
        
        def im_convert(tensor):
            image = tensor.clone().detach().numpy()
            image = image.transpose(1, 2, 0)
            image = image * (np.array((0.5,0.5,0.5)) + np.array((0.5,0.5,0.5)))
            image = image.clip(0, 1)
            return image
        
        classes = {0:'cat', 1:'dog'}
        
        dataiter = iter(test_loader)  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
        images, labels = next(dataiter)
        output = model(images)
        _, preds = torch.max(output, 1)
        
        fig = plt.figure(figsize=(25,4))
        for idx in np.arange(20):
            ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
            plt.imshow(im_convert(images[idx]))
            a.set_title(classes[labels[i].item()])
        ax.set_title("{}({})".format(str(classes[preds[idx].item()]), str(classes[labels[idx].
                     item()])), color=("green" if preds[idx]==labels[idx] else "red"))
        plt.show()
        plt.subplots_adjust(bottom=0.2, top=0.6, hspace=0)
        ```
        
    - ğŸ’» Code (RandomResizedCrop ë°ì´í„° í™•ì¥)
        
        ```python
        !pip install mxnet
        !pip install --user mxnet
        
        import matplotlib.pyplot as plt
        import mxnet as mx
        from mxnet.gluon.data.vision import transforms
        
        example_image = mx.image.imread("chap05/data/cat.jpg")
        plt.imshow(example_image.asnumpy())
        
        def show_images(imgs, num_rows, num_cols, scale=2):
            aspect_ratio = imgs[0].shape[0]/imgs[0].shape[1]  # í™•ì¥í•  ì´ë¯¸ì§€ì˜ í¬ê¸° ì¡°ì •
            figsize = (num_cols * scale, num_rows * scale * aspect_ratio)
            _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)
            for i in range(num_rows):
                for j in range(num_cols):
                    axes[i][j].imshow(imgs[i * num_cols + j].asnumpy())
                    axes[i][j].axes.get_xaxis().set_visible(False)
                    axes[i][j].axes.get_yaxis().set_visible(False)
            plt.subplots_adjust(hspace=0.1, wspace=0)
            return axes
        
        def apply(img, aug, num_rows=2, num_cols=4, scale=3):
            Y = [aug(img) for _ in range(num_rows * num_cols)]  # ë°ì´í„° í™•ì¥ ì ìš©
            show_images(Y, num_rows, num_cols, scale)
            
        shape_aug = transforms.RandomResizedCrop(size=(200, 200),
                                                 scale=(0.1, 1),
                                                 ratio=(0.5, 2))
        apply(example_image, shape_aug)
        ```
        
- **íŠ¹ì„± ë§µ ì‹œê°í™”**
    - **ì„¤ëª… ê°€ëŠ¥í•œ CNN(Explainable CNN)** : ë”¥ëŸ¬ë‹ ì²˜ë¦¬ ê²°ê³¼ë¥¼ ì‚¬ëŒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë°©ì‹ìœ¼ë¡œ ì œì‹œí•˜ëŠ” ê¸°ìˆ  â†’ í•„í„° ì‹œê°í™”, íŠ¹ì„± ë§µ ì‹œê°í™”
    - **íŠ¹ì„± ë§µ(Feature Map)** : í•„í„°ë¥¼ ì…ë ¥ì— ì ìš©í•œ ê²°ê³¼ *(ì…ë ¥ íŠ¹ì„±ì„ ê°ì§€í•˜ëŠ” ë°©ë²•!*)
    - ğŸ’» Code
        
        ```python
        !pip install pillow
        
        import matplotlib.pyplot as plt
        from PIL import Image
        import cv2
        import torch
        import torch.nn.functional as F
        import torch.nn as nn
        from torchvision.transforms import ToTensor
        import torchvision
        import torchvision.transforms as transforms
        import torchvision.models as models
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        class XAI(torch.nn.Module):
            def __init__(self, num_classes=2):
                super(XAI, self).__init__()
                self.features = nn.Sequential(
                    nn.Conv2d(3, 64, kernel_size=3, bias=False),
                    nn.BatchNorm2d(64),
                    nn.ReLU(inplace=True),  # inplace=TrueëŠ” ê¸°ì¡´ì˜ ë°ì´í„°ë¥¼ ì—°ì‚°ì˜ ê²°ê´ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ê²ƒì„ ì˜ë¯¸
                    nn.Dropout(0.3),
                    nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(64),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
        
                    nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(128),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.4),
                    nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(128),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
        
                    nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(256),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.4),
                    nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(256),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.4),
                    nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(256),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
        
                    nn.Conv2d(256, 512, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(512),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.4),
                    nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(512),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.4),
                    nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(512),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
        
                    nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(512),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.4),
                    nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(512),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.4),
                    nn.Conv2d(512, 512, kernel_size=3, padding=1, bias=False),
                    nn.BatchNorm2d(512),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                )
                self.classifier = nn.Sequential(
                    nn.Linear(512, 512, bias=False),
                    nn.Dropout(0.5),
                    nn.BatchNorm1d(512),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.5),
                    nn.Linear(512, num_classes)
                )
        
            def forward(self, x):
                x = self.features(x)
                x = x.view(-1, 512)
                x = self.classifier(x)
                return F.log_softmax(x)
                
        model = XAI()  # modelì´ë¼ëŠ” ì´ë¦„ì˜ ê°ì²´ë¥¼ ìƒì„±
        model.to(device)
        model.eval()
        
        class LayerActivations:
            features = []
            def __init__(self, model, layer_num):
                self.hook = model[layer_num].register_forward_hook(self.hook_fn)
        
            def hook_fn(self, module, input, output):
                self.features = output.detach().numpy()
        
            def remove(self):  # hook ì‚­ì œ
                self.hook.remove()
                
        img = cv2.imread("chap05/data/cat.jpg")
        plt.imshow(img)
        img = cv2.resize(img, (100,100), interpolation=cv2.INTER_LINEAR)
        img = ToTensor()(img).unsqueeze(0)
        print(img.shape)
        
        result = LayerActivations(model.features, 0)  # 0ë²ˆì§¸ Conv2d íŠ¹ì„± ë§µ í™•ì¸
        
        model(img)
        activations = result.features
        
        fig, axes = plt.subplots(4, 4)
        fig = plt.figure(figsize=(12,8))
        fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)
        for row in range(4):
            for column in range(4):
                axis = axes[row][column]
                axis.get_xaxis().set_ticks([])
                axis.get_yaxis().set_ticks([])
                axis.imshow(activations[0][row*10+column])
        plt.show()
        
        result = LayerActivations(model.features, 20)  # 20ë²ˆì§¸ Conv2d íŠ¹ì„± ë§µ í™•ì¸
        
        model(img)
        activations = result.features
        
        fig, axes = plt.subplots(4, 4)
        fig = plt.figure(figsize=(12,8))
        fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)
        for row in range(4):
            for column in range(4):
                axis = axes[row][column]
                axis.get_xaxis().set_ticks([])
                axis.get_yaxis().set_ticks([])
                axis.imshow(activations[0][row*10+column])
        plt.show()
        
        result = LayerActivations(model.features, 40)  # 40ë²ˆì§¸ Conv2d íŠ¹ì„± ë§µ í™•ì¸
        
        model(img)
        activations = result.features
        
        fig, axes = plt.subplots(4, 4)
        fig = plt.figure(figsize=(12,8))
        fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)
        for row in range(4):
            for column in range(4):
                axis = axes[row][column]
                axis.get_xaxis().set_ticks([])
                axis.get_yaxis().set_ticks([])
                axis.imshow(activations[0][row*10+column])
        plt.show()
        ```
        
- **ê·¸ë˜í”„ í•©ì„±ê³± ë„¤íŠ¸ì›Œí¬**
    - **ê·¸ë˜í”„ í•©ì„±ê³± ë„¤íŠ¸ì›Œí¬(Graph Convolutional Network)** : ì—ì§€ë¡œ ì—°ê²°ëœ ë…¸ë“œì˜ ì§‘í•© (ë…¸ë“œ + ì—ì§€)
    - **ê·¸ë˜í”„ ì‹ ê²½ë§(Graph Neural Network, GNN)** : ê·¸ë˜í”„ êµ¬ì¡° ì‹ ê²½ë§
        
        ![image.png](attachment:158717a0-c9ad-46f5-afa9-24b000b69225:image.png)
        
    - **ê·¸ë˜í”„ í‘œí˜„ ë°©ë²•** : ì¸ì ‘ í–‰ë ¬(Adjacency Matrix), íŠ¹ì„± í–‰ë ¬(Feature Matrix, ì´ìš©í•  íŠ¹ì„± ì„ íƒ)
    - **ë¦¬ë“œì•„ì›ƒ(Readout)** : íŠ¹ì„± í–‰ë ¬ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (íŠ¹ì„± ë²¡í„° í‰ê· ì„ êµ¬í•˜ì—¬ ê·¸ë˜í”„ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ í‘œí˜„)

### **ğŸ¤” ë” ì•Œì•„ë³´ê¸°**

- ìŒì„±ì¸ì‹ì—ì„œë„ CNNì„ ì‚¬ìš©í•œë‹¤?

[êµ¬ê¸€ ë¸Œë ˆì¸ íŒ€ì—ê²Œ ë°°ìš°ëŠ” ë”¥ëŸ¬ë‹ with TensorFlow.js: 4.4.1 ìŠ¤í™íŠ¸ë¡œê·¸ë¨: ì‚¬ìš´ë“œë¥¼ ì´ë¯¸ì§€ë¡œ í‘œí˜„í•˜ê¸° - 1](https://thebook.io/080237/0215/)

- ë¯¸ë‹ˆ ë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²•ì´ ë¹ ë¥¸ ì´ìœ ëŠ”? â†’ í–‰ë ¬ ì—°ì‚°ì„ í™œìš©í•œ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
- 1D, 2D, 3D í•©ì„±ê³±ì´ ë”°ë¡œë”°ë¡œ í•„ìš”í•œê°€? â†’ í•„í„°ì˜ ì´ë™ ë°©í–¥ì— ë”°ë¥¸ êµ¬ë¶„

[11-02 ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ 1D CNN(1D Convolutional Neural Networks)](https://wikidocs.net/80437)

- DataLoaderëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ì§€?

[5. Dataset ê³¼ DataLoader](https://wikidocs.net/156998)